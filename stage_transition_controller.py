"""
Stage Transition Controller

A finite state automaton implementation for validating canonical pipeline stage 
transitions according to the I→X→K→A→L→R→O→G→T→S sequence. Provides methods to 
verify artifact presence between stages, detect hash continuity breaks, and implement 
runtime import monitoring to prevent backward dependencies that violate DAG architecture.

Features:
- FSM-based transition validation with strict ordering
- Artifact verification with SHA-256 checksums
- Hash continuity detection across the processing chain
- Runtime import interception to detect backward dependencies
- Comprehensive logging with structured output for debugging/compliance
- Detailed error messages with remediation suggestions
"""

import hashlib
import importlib.util
import json
import logging
import os
import sys
import threading
import time
from contextlib import contextmanager
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum, auto
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple, Union
from collections import defaultdict
import builtins

# Configure structured logging
logger = logging.getLogger(__name__)


class StageState(Enum):
    """Valid pipeline stages in canonical order I→X→K→A→L→R→O→G→T→S"""
    INGESTION_PREPARATION = "I"
    CONTEXT_CONSTRUCTION = "X" 
    KNOWLEDGE_EXTRACTION = "K"
    ANALYSIS_NLP = "A"
    CLASSIFICATION_EVALUATION = "L"
    SEARCH_RETRIEVAL = "R"
    ORCHESTRATION_CONTROL = "O"
    AGGREGATION_REPORTING = "G"
    INTEGRATION_STORAGE = "T"
    SYNTHESIS_OUTPUT = "S"


class ValidationResult(Enum):
    """Validation result types"""
    SUCCESS = auto()
    INVALID_TRANSITION = auto()
    MISSING_ARTIFACT = auto()
    HASH_MISMATCH = auto()
    BACKWARD_DEPENDENCY = auto()
    POLICY_VIOLATION = auto()


@dataclass
class Artifact:
    """Represents an artifact generated by a pipeline stage"""
    file_path: str
    stage: StageState
    content_hash: str
    created_at: datetime
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def verify_existence(self) -> bool:
        """Check if artifact file exists"""
        return Path(self.file_path).exists()
    
    def compute_hash(self) -> str:
        """Compute SHA-256 hash of artifact content"""
        try:
            with open(self.file_path, 'rb') as f:
                content = f.read()
                return hashlib.sha256(content).hexdigest()
        except Exception as e:
            logger.error(f"Failed to compute hash for {self.file_path}: {e}")
            return ""
    
    def verify_integrity(self) -> bool:
        """Verify artifact integrity by comparing stored and computed hashes"""
        if not self.verify_existence():
            return False
        
        current_hash = self.compute_hash()
        return current_hash == self.content_hash


@dataclass
class TransitionResult:
    """Result of a stage transition attempt"""
    from_stage: StageState
    to_stage: StageState
    result: ValidationResult
    message: str
    timestamp: datetime = field(default_factory=datetime.now)
    artifacts_verified: List[str] = field(default_factory=list)
    hash_continuity_breaks: List[str] = field(default_factory=list)
    backward_dependencies: List[str] = field(default_factory=list)
    remediation_suggestions: List[str] = field(default_factory=list)


@dataclass 
class ImportViolation:
    """Represents a detected backward dependency violation"""
    importing_module: str
    imported_module: str
    importing_stage: StageState
    imported_stage: StageState
    timestamp: datetime
    call_stack: List[str]


class ImportMonitor:
    """Runtime import monitoring to detect backward dependencies"""
    
    def __init__(self, stage_module_mapping: Dict[str, StageState]):
        self.stage_module_mapping = stage_module_mapping
        self.violations: List[ImportViolation] = []
        self.original_import = builtins.__import__
        self.current_stage: Optional[StageState] = None
        self.monitoring_active = False
        self._lock = threading.Lock()
    
    def _get_stage_for_module(self, module_name: str) -> Optional[StageState]:
        """Determine which stage a module belongs to"""
        for prefix, stage in self.stage_module_mapping.items():
            if module_name.startswith(prefix):
                return stage
        return None
    
    def _is_backward_dependency(self, importing_stage: StageState, 
                              imported_stage: StageState) -> bool:
        """Check if import represents backward dependency in DAG"""
        if importing_stage is None or imported_stage is None:
            return False
            
        # Get stage order values
        stage_order = {stage: i for i, stage in enumerate(StageState)}
        importing_order = stage_order.get(importing_stage, -1)
        imported_order = stage_order.get(imported_stage, -1)
        
        # Backward dependency if importing from later stage
        return imported_order > importing_order
    
    def _get_call_stack(self) -> List[str]:
        """Get current call stack for debugging"""
        import traceback
        return traceback.format_stack()[:-1]  # Exclude current frame
    
    def _monitored_import(self, name, globals=None, locals=None, fromlist=(), level=0):
        """Replacement import function that monitors dependencies"""
        try:
            # Call original import first
            module = self.original_import(name, globals, locals, fromlist, level)
            
            # Only monitor during active stage execution
            if not self.monitoring_active or self.current_stage is None:
                return module
            
            with self._lock:
                # Determine stages
                importing_stage = self.current_stage
                imported_stage = self._get_stage_for_module(name)
                
                if self._is_backward_dependency(importing_stage, imported_stage):
                    violation = ImportViolation(
                        importing_module=globals.get('__name__', '<unknown>') if globals else '<unknown>',
                        imported_module=name,
                        importing_stage=importing_stage,
                        imported_stage=imported_stage,
                        timestamp=datetime.now(),
                        call_stack=self._get_call_stack()
                    )
                    
                    self.violations.append(violation)
                    
                    logger.error(
                        f"Backward dependency detected: {importing_stage.value} -> {imported_stage.value} "
                        f"(module: {name})"
                    )
            
            return module
            
        except Exception as e:
            logger.error(f"Import monitoring error for {name}: {e}")
            # Fall back to original import
            return self.original_import(name, globals, locals, fromlist, level)
    
    def start_monitoring(self, stage: StageState):
        """Start monitoring imports for a specific stage"""
        with self._lock:
            self.current_stage = stage
            self.monitoring_active = True
            builtins.__import__ = self._monitored_import
            logger.info(f"Started import monitoring for stage {stage.value}")
    
    def stop_monitoring(self):
        """Stop import monitoring and restore original import"""
        with self._lock:
            self.monitoring_active = False
            self.current_stage = None
            builtins.__import__ = self.original_import
            logger.info("Stopped import monitoring")
    
    def get_violations(self) -> List[ImportViolation]:
        """Get all detected violations"""
        with self._lock:
            return self.violations.copy()
    
    def clear_violations(self):
        """Clear violation history"""
        with self._lock:
            self.violations.clear()


class StageTransitionController:
    """
    Finite State Automaton for validating canonical pipeline stage transitions.
    
    Enforces the canonical sequence: I→X→K→A→L→R→O→G→T→S
    """
    
    # Define valid transitions in the canonical sequence
    VALID_TRANSITIONS = {
        StageState.INGESTION_PREPARATION: [StageState.CONTEXT_CONSTRUCTION],
        StageState.CONTEXT_CONSTRUCTION: [StageState.KNOWLEDGE_EXTRACTION],
        StageState.KNOWLEDGE_EXTRACTION: [StageState.ANALYSIS_NLP],
        StageState.ANALYSIS_NLP: [StageState.CLASSIFICATION_EVALUATION],
        StageState.CLASSIFICATION_EVALUATION: [StageState.SEARCH_RETRIEVAL],
        StageState.SEARCH_RETRIEVAL: [StageState.ORCHESTRATION_CONTROL],
        StageState.ORCHESTRATION_CONTROL: [StageState.AGGREGATION_REPORTING],
        StageState.AGGREGATION_REPORTING: [StageState.INTEGRATION_STORAGE],
        StageState.INTEGRATION_STORAGE: [StageState.SYNTHESIS_OUTPUT],
        StageState.SYNTHESIS_OUTPUT: []  # Terminal state
    }
    
    # Module prefix to stage mapping for import monitoring
    DEFAULT_STAGE_MODULE_MAPPING = {
        'ingestion_': StageState.INGESTION_PREPARATION,
        'context_': StageState.CONTEXT_CONSTRUCTION,
        'knowledge_': StageState.KNOWLEDGE_EXTRACTION,
        'analysis_': StageState.ANALYSIS_NLP,
        'classification_': StageState.CLASSIFICATION_EVALUATION,
        'search_': StageState.SEARCH_RETRIEVAL,
        'orchestration_': StageState.ORCHESTRATION_CONTROL,
        'aggregation_': StageState.AGGREGATION_REPORTING,
        'integration_': StageState.INTEGRATION_STORAGE,
        'synthesis_': StageState.SYNTHESIS_OUTPUT,
    }
    
    def __init__(self, 
                 artifact_directory: str = "artifacts",
                 log_file: str = "stage_transitions.log",
                 stage_module_mapping: Optional[Dict[str, StageState]] = None):
        """
        Initialize Stage Transition Controller.
        
        Args:
            artifact_directory: Directory to store stage artifacts
            log_file: Path to transition log file
            stage_module_mapping: Custom module prefix to stage mapping
        """
        self.artifact_directory = Path(artifact_directory)
        self.artifact_directory.mkdir(parents=True, exist_ok=True)
        
        self.current_stage: Optional[StageState] = None
        self.artifacts: Dict[StageState, List[Artifact]] = defaultdict(list)
        self.transition_history: List[TransitionResult] = []
        
        # Configure logging
        self.log_file = Path(log_file)
        self._setup_logging()
        
        # Initialize import monitoring
        module_mapping = stage_module_mapping or self.DEFAULT_STAGE_MODULE_MAPPING
        self.import_monitor = ImportMonitor(module_mapping)
        
        logger.info("StageTransitionController initialized")
        logger.info(f"Artifact directory: {self.artifact_directory}")
        logger.info(f"Log file: {self.log_file}")
    
    def _setup_logging(self):
        """Configure structured logging for transitions and violations"""
        # Create file handler for transition logs
        handler = logging.FileHandler(self.log_file)
        handler.setLevel(logging.INFO)
        
        # Create detailed formatter for structured output
        formatter = logging.Formatter(
            '%(asctime)s | %(levelname)s | %(name)s | %(funcName)s:%(lineno)d | %(message)s'
        )
        handler.setFormatter(formatter)
        
        # Add handler to logger
        logger.addHandler(handler)
        logger.setLevel(logging.INFO)
    
    def is_valid_transition(self, from_stage: StageState, to_stage: StageState) -> bool:
        """Check if transition between stages is valid according to FSM"""
        if from_stage is None:
            # Allow starting from ingestion
            return to_stage == StageState.INGESTION_PREPARATION
        
        valid_next_stages = self.VALID_TRANSITIONS.get(from_stage, [])
        return to_stage in valid_next_stages
    
    def register_artifact(self, 
                         stage: StageState, 
                         file_path: str,
                         metadata: Optional[Dict[str, Any]] = None) -> Artifact:
        """
        Register an artifact for a specific stage.
        
        Args:
            stage: The stage that generated this artifact
            file_path: Path to the artifact file
            metadata: Optional metadata about the artifact
            
        Returns:
            Artifact object with computed hash
        """
        artifact_path = Path(file_path)
        if not artifact_path.exists():
            raise FileNotFoundError(f"Artifact file not found: {file_path}")
        
        # Compute content hash
        with open(artifact_path, 'rb') as f:
            content = f.read()
            content_hash = hashlib.sha256(content).hexdigest()
        
        artifact = Artifact(
            file_path=str(artifact_path),
            stage=stage,
            content_hash=content_hash,
            created_at=datetime.now(),
            metadata=metadata or {}
        )
        
        self.artifacts[stage].append(artifact)
        
        logger.info(f"Registered artifact for stage {stage.value}: {file_path} (hash: {content_hash[:8]}...)")
        return artifact
    
    def verify_artifacts_present(self, stage: StageState) -> Tuple[bool, List[str]]:
        """
        Verify all artifacts for a stage are present and intact.
        
        Args:
            stage: Stage to verify artifacts for
            
        Returns:
            (success, missing_files)
        """
        missing_files = []
        stage_artifacts = self.artifacts.get(stage, [])
        
        if not stage_artifacts:
            logger.warning(f"No artifacts registered for stage {stage.value}")
            return False, ["No artifacts registered"]
        
        for artifact in stage_artifacts:
            if not artifact.verify_existence():
                missing_files.append(artifact.file_path)
            elif not artifact.verify_integrity():
                missing_files.append(f"{artifact.file_path} (integrity check failed)")
        
        success = len(missing_files) == 0
        if success:
            logger.info(f"All artifacts verified for stage {stage.value}")
        else:
            logger.error(f"Missing/corrupted artifacts for stage {stage.value}: {missing_files}")
        
        return success, missing_files
    
    def detect_hash_continuity_breaks(self) -> List[str]:
        """
        Detect breaks in hash continuity across the processing chain.
        
        Verifies that artifacts maintain their expected hashes throughout
        the pipeline execution.
        
        Returns:
            List of detected continuity breaks
        """
        breaks = []
        
        for stage, artifacts in self.artifacts.items():
            for artifact in artifacts:
                if not artifact.verify_integrity():
                    break_msg = f"Hash continuity break in {stage.value}: {artifact.file_path}"
                    breaks.append(break_msg)
                    logger.error(break_msg)
        
        return breaks
    
    def _generate_remediation_suggestions(self, 
                                        result: ValidationResult,
                                        from_stage: Optional[StageState] = None,
                                        to_stage: Optional[StageState] = None,
                                        missing_artifacts: Optional[List[str]] = None,
                                        violations: Optional[List[ImportViolation]] = None) -> List[str]:
        """Generate specific remediation suggestions based on validation failure"""
        suggestions = []
        
        if result == ValidationResult.INVALID_TRANSITION:
            if from_stage and to_stage:
                valid_next = self.VALID_TRANSITIONS.get(from_stage, [])
                suggestions.append(
                    f"Invalid transition {from_stage.value}→{to_stage.value}. "
                    f"Valid next stages from {from_stage.value}: {[s.value for s in valid_next]}"
                )
                suggestions.append("Review pipeline configuration to follow canonical I→X→K→A→L→R→O→G→T→S sequence")
        
        elif result == ValidationResult.MISSING_ARTIFACT:
            suggestions.append("Ensure all required artifacts are generated before stage transition")
            if missing_artifacts:
                suggestions.append(f"Missing artifacts: {missing_artifacts}")
                suggestions.append("Check previous stage completion and output generation")
        
        elif result == ValidationResult.HASH_MISMATCH:
            suggestions.append("Verify artifact integrity - files may have been corrupted or modified")
            suggestions.append("Consider regenerating artifacts from previous stage")
            suggestions.append("Check file system permissions and storage stability")
        
        elif result == ValidationResult.BACKWARD_DEPENDENCY:
            suggestions.append("Remove import statements that create backward dependencies")
            if violations:
                for violation in violations:
                    suggestions.append(
                        f"Remove import of {violation.imported_module} from {violation.importing_module} "
                        f"(stage {violation.importing_stage.value} should not import from stage {violation.imported_stage.value})"
                    )
            suggestions.append("Refactor code to follow DAG architecture with forward-only dependencies")
        
        elif result == ValidationResult.POLICY_VIOLATION:
            suggestions.append("Review and comply with pipeline execution policies")
            suggestions.append("Check stage prerequisites and dependency requirements")
        
        return suggestions
    
    @contextmanager
    def stage_execution_context(self, stage: StageState):
        """
        Context manager for stage execution with import monitoring.
        
        Args:
            stage: Stage being executed
            
        Usage:
            with controller.stage_execution_context(StageState.KNOWLEDGE_EXTRACTION):
                # Stage execution code here
                pass
        """
        logger.info(f"Starting execution context for stage {stage.value}")
        
        # Start import monitoring
        self.import_monitor.start_monitoring(stage)
        
        try:
            yield
        finally:
            # Stop import monitoring
            self.import_monitor.stop_monitoring()
            logger.info(f"Completed execution context for stage {stage.value}")
    
    def validate_transition(self, 
                          from_stage: Optional[StageState], 
                          to_stage: StageState,
                          require_artifacts: bool = True) -> TransitionResult:
        """
        Validate a stage transition according to FSM rules.
        
        Args:
            from_stage: Source stage (None for initial transition)
            to_stage: Target stage
            require_artifacts: Whether to verify artifact presence
            
        Returns:
            TransitionResult with validation outcome
        """
        logger.info(f"Validating transition {from_stage.value if from_stage else 'None'} → {to_stage.value}")
        
        # Check if transition is valid according to FSM
        if not self.is_valid_transition(from_stage, to_stage):
            result = TransitionResult(
                from_stage=from_stage,
                to_stage=to_stage,
                result=ValidationResult.INVALID_TRANSITION,
                message=f"Invalid transition: {from_stage.value if from_stage else 'None'} → {to_stage.value}",
                remediation_suggestions=self._generate_remediation_suggestions(
                    ValidationResult.INVALID_TRANSITION, from_stage, to_stage
                )
            )
            self.transition_history.append(result)
            return result
        
        # Verify artifacts from previous stage if required
        missing_artifacts = []
        if require_artifacts and from_stage is not None:
            artifacts_valid, missing = self.verify_artifacts_present(from_stage)
            if not artifacts_valid:
                result = TransitionResult(
                    from_stage=from_stage,
                    to_stage=to_stage,
                    result=ValidationResult.MISSING_ARTIFACT,
                    message=f"Missing artifacts from stage {from_stage.value}",
                    artifacts_verified=[],
                    remediation_suggestions=self._generate_remediation_suggestions(
                        ValidationResult.MISSING_ARTIFACT, missing_artifacts=missing
                    )
                )
                self.transition_history.append(result)
                return result
            missing_artifacts = missing
        
        # Check for hash continuity breaks
        hash_breaks = self.detect_hash_continuity_breaks()
        if hash_breaks:
            result = TransitionResult(
                from_stage=from_stage,
                to_stage=to_stage,
                result=ValidationResult.HASH_MISMATCH,
                message="Hash continuity breaks detected",
                hash_continuity_breaks=hash_breaks,
                remediation_suggestions=self._generate_remediation_suggestions(
                    ValidationResult.HASH_MISMATCH
                )
            )
            self.transition_history.append(result)
            return result
        
        # Check for backward dependency violations
        violations = self.import_monitor.get_violations()
        if violations:
            result = TransitionResult(
                from_stage=from_stage,
                to_stage=to_stage,
                result=ValidationResult.BACKWARD_DEPENDENCY,
                message=f"Backward dependency violations detected: {len(violations)}",
                backward_dependencies=[
                    f"{v.importing_module} → {v.imported_module}" for v in violations
                ],
                remediation_suggestions=self._generate_remediation_suggestions(
                    ValidationResult.BACKWARD_DEPENDENCY, violations=violations
                )
            )
            self.transition_history.append(result)
            return result
        
        # Transition is valid
        self.current_stage = to_stage
        result = TransitionResult(
            from_stage=from_stage,
            to_stage=to_stage,
            result=ValidationResult.SUCCESS,
            message=f"Valid transition: {from_stage.value if from_stage else 'Start'} → {to_stage.value}",
            artifacts_verified=[a.file_path for a in self.artifacts.get(from_stage, [])]
        )
        
        self.transition_history.append(result)
        logger.info(f"Validated transition successfully: {from_stage.value if from_stage else 'Start'} → {to_stage.value}")
        
        return result
    
    def get_current_stage(self) -> Optional[StageState]:
        """Get the current stage in the FSM"""
        return self.current_stage
    
    def get_next_valid_stages(self) -> List[StageState]:
        """Get list of valid next stages from current state"""
        if self.current_stage is None:
            return [StageState.INGESTION_PREPARATION]
        
        return self.VALID_TRANSITIONS.get(self.current_stage, [])
    
    def get_transition_history(self) -> List[TransitionResult]:
        """Get complete transition history"""
        return self.transition_history.copy()
    
    def get_compliance_report(self) -> Dict[str, Any]:
        """
        Generate comprehensive compliance report for debugging and auditing.
        
        Returns:
            Structured compliance report with all validation activities
        """
        violations = self.import_monitor.get_violations()
        failed_transitions = [t for t in self.transition_history if t.result != ValidationResult.SUCCESS]
        
        report = {
            "timestamp": datetime.now().isoformat(),
            "current_stage": self.current_stage.value if self.current_stage else None,
            "total_transitions": len(self.transition_history),
            "successful_transitions": len(self.transition_history) - len(failed_transitions),
            "failed_transitions": len(failed_transitions),
            
            "artifact_summary": {
                stage.value: {
                    "count": len(artifacts),
                    "files": [a.file_path for a in artifacts],
                    "all_verified": all(a.verify_integrity() for a in artifacts)
                }
                for stage, artifacts in self.artifacts.items()
            },
            
            "import_violations": {
                "total_violations": len(violations),
                "violations_by_stage": {
                    stage.value: len([v for v in violations if v.importing_stage == stage])
                    for stage in StageState
                },
                "detailed_violations": [
                    {
                        "importing_module": v.importing_module,
                        "imported_module": v.imported_module,
                        "importing_stage": v.importing_stage.value,
                        "imported_stage": v.imported_stage.value,
                        "timestamp": v.timestamp.isoformat()
                    }
                    for v in violations
                ]
            },
            
            "failed_transition_details": [
                {
                    "from_stage": t.from_stage.value if t.from_stage else None,
                    "to_stage": t.to_stage.value,
                    "result": t.result.name,
                    "message": t.message,
                    "timestamp": t.timestamp.isoformat(),
                    "remediation_suggestions": t.remediation_suggestions
                }
                for t in failed_transitions
            ],
            
            "hash_continuity": {
                "breaks_detected": len(self.detect_hash_continuity_breaks()),
                "details": self.detect_hash_continuity_breaks()
            }
        }
        
        return report
    
    def export_compliance_report(self, output_file: str):
        """Export compliance report to JSON file"""
        report = self.get_compliance_report()
        
        with open(output_file, 'w') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Compliance report exported to {output_file}")
    
    def reset_state(self):
        """Reset controller to initial state"""
        logger.info("Resetting StageTransitionController state")
        
        self.current_stage = None
        self.artifacts.clear()
        self.transition_history.clear()
        self.import_monitor.clear_violations()
        
        logger.info("State reset completed")


# Convenience functions for common usage patterns

def create_controller(artifact_dir: str = "artifacts", 
                     log_file: str = "stage_transitions.log") -> StageTransitionController:
    """Create a new StageTransitionController with default settings"""
    return StageTransitionController(artifact_dir, log_file)


def validate_pipeline_sequence(controller: StageTransitionController,
                              stages: List[StageState],
                              require_artifacts: bool = False) -> List[TransitionResult]:
    """
    Validate a complete pipeline sequence.
    
    Args:
        controller: StageTransitionController instance
        stages: List of stages to validate in order
        require_artifacts: Whether to require artifacts for transitions
        
    Returns:
        List of transition results
    """
    results = []
    current_stage = None
    
    for stage in stages:
        result = controller.validate_transition(current_stage, stage, require_artifacts=require_artifacts)
        results.append(result)
        
        if result.result == ValidationResult.SUCCESS:
            current_stage = stage
        else:
            # Stop validation on first failure
            break
    
    return results


# Example usage and testing utilities
if __name__ == "__main__":
    # Example usage
    controller = create_controller()
    
    # Test canonical sequence
    canonical_stages = [
        StageState.INGESTION_PREPARATION,
        StageState.CONTEXT_CONSTRUCTION,
        StageState.KNOWLEDGE_EXTRACTION,
        StageState.ANALYSIS_NLP,
        StageState.CLASSIFICATION_EVALUATION,
        StageState.SEARCH_RETRIEVAL,
        StageState.ORCHESTRATION_CONTROL,
        StageState.AGGREGATION_REPORTING,
        StageState.INTEGRATION_STORAGE,
        StageState.SYNTHESIS_OUTPUT
    ]
    
    print("Testing canonical pipeline sequence...")
    results = validate_pipeline_sequence(controller, canonical_stages)
    
    for result in results:
        status = "✓" if result.result == ValidationResult.SUCCESS else "✗"
        transition = f"{result.from_stage.value if result.from_stage else 'Start'} → {result.to_stage.value}"
        print(f"{status} {transition}: {result.message}")
    
    # Generate compliance report
    print("\nGenerating compliance report...")
    controller.export_compliance_report("transition_compliance_report.json")
    print("Report saved to transition_compliance_report.json")