# Comprehensive Audit Logging System

## Overview

This document describes the comprehensive audit logging system implemented across all stages of the EGW Query Expansion pipeline. The system provides standardized execution tracing, timing metrics, error handling, and state transitions with complete integration into existing TotalOrderingBase components.

## Key Features

- **Standardized _audit.json files** with consistent structure across all stages
- **Complete execution traceability** with start_time, end_time, duration_ms
- **File tracking** with input_files and output_files logging
- **Status monitoring** with success/partial/failed status indicators
- **Error handling** with error_count, warnings, and detailed error information
- **State transitions** tracking with timestamps and triggers
- **Performance metrics** including memory usage and CPU time
- **UTF-8 encoding** with indent=2 formatting for consistency
- **Cross-stage compatibility** working with all implemented stages

## Architecture

### Core Components

1. **AuditLogger** (`audit_logger.py`)
   - Primary audit logging functionality
   - Session lifecycle management
   - State transition tracking
   - Performance metrics collection

2. **AuditMixin** (`audit_logger.py`)
   - Mixin for TotalOrderingBase integration
   - Automatic audit capabilities for existing components
   - Non-disruptive integration pattern

3. **Enhanced TotalOrderingBase** (`total_ordering_base.py`)
   - Integrated audit logging support
   - Backward compatibility maintained
   - Optional audit features

## File Structure and Naming Convention

Audit files are generated following a standardized pattern:

```
canonical_flow/<stage_name>/<document_stem>_audit.json
```

### Examples:
- `canonical_flow/A_analysis_nlp/document_123_audit.json`
- `canonical_flow/G_aggregation_reporting/report_001_audit.json`

### Supported Stages:
- `A_analysis_nlp` - Analysis NLP components
- `G_aggregation_reporting` - Aggregation and reporting components

## Audit File Format

### Standard Structure

Every audit file contains the following standardized fields:

```json
{
  "component_name": "ComponentName",
  "operation_id": "op_abc123def456",
  "stage_name": "A_analysis_nlp",
  "document_stem": "document_123",
  "start_time": "2024-01-15T10:30:45.123456",
  "end_time": "2024-01-15T10:30:47.654321",
  "duration_ms": 2530.865,
  "input_files": [
    "/path/to/input.pdf",
    "/path/to/config.json"
  ],
  "output_files": [
    "/path/to/output.json",
    "/path/to/summary.txt"
  ],
  "status": "success",
  "error_count": 0,
  "warnings": [
    "Minor processing warning: low confidence score"
  ],
  "state_transitions": [
    {
      "from_state": "initialized",
      "to_state": "processing", 
      "timestamp": "2024-01-15T10:30:45.200000",
      "trigger": "start_processing",
      "metadata": {"input_count": 2}
    }
  ],
  "metadata": {
    "processing_config": {"threads": 4},
    "user_context": {"user_id": "demo"}
  },
  "execution_environment": {
    "hostname": "demo-machine",
    "platform": "Linux-5.4.0",
    "python_version": "3.9.7",
    "working_directory": "/project/root"
  },
  "performance_metrics": {
    "execution_time_seconds": 2.531,
    "files_processed": 2,
    "files_generated": 2,
    "memory_peak_mb": 145.2,
    "cpu_time_seconds": 1.23
  }
}
```

### Status Values

- `"success"` - Processing completed successfully
- `"partial"` - Processing completed with warnings or partial results
- `"failed"` - Processing failed with errors

### State Transitions

Each state transition includes:
- `from_state` - Previous state name
- `to_state` - New state name  
- `timestamp` - ISO format timestamp
- `trigger` - What caused the transition
- `metadata` - Additional transition context

## Integration with Existing Components

### TotalOrderingBase Integration

The audit system seamlessly integrates with existing TotalOrderingBase components:

```python
class ExampleComponent(TotalOrderingBase):
    def __init__(self):
        super().__init__("ExampleComponent")
        self.stage_name = "A_analysis_nlp"  # Set for audit logging
    
    def process(self, data=None, context=None):
        # Use audit-enabled processing if available
        if hasattr(self, 'process_with_audit'):
            return self.process_with_audit(data, context)
        
        # Fallback to standard processing
        # ... existing implementation
```

### Implemented Components

#### Analysis NLP Stage (A_analysis_nlp)

- âœ… **AdaptiveAnalyzer** - Enhanced with audit logging
- âœ… **QuestionAnalyzer** - Enhanced with audit logging
- ðŸ”„ **ImplementacionMapeo** - Ready for enhancement
- ðŸ”„ **EvidenceProcessor** - Ready for enhancement
- ðŸ”„ **EvaluationDrivenProcessor** - Ready for enhancement
- ðŸ”„ **DNPAlignmentAdapter** - Ready for enhancement
- ðŸ”„ **ExtractorEvidenciasContextual** - Ready for enhancement
- ðŸ”„ **EvidenceValidationModel** - Ready for enhancement

#### Aggregation Reporting Stage (G_aggregation_reporting)

- âœ… **MesoAggregator** - Enhanced with audit logging
- ðŸ”„ **ReportCompiler** - Ready for enhancement

## Usage Examples

### Manual Audit Logging

```python
from audit_logger import AuditLogger, AuditStatus

# Create audit logger
logger = AuditLogger("MyComponent", "A_analysis_nlp")

# Start audit session
entry = logger.start_audit(
    document_stem="my_document",
    operation_id="my_op_001",
    input_files=["input.pdf"],
    metadata={"version": "1.0"}
)

# Log processing steps
logger.log_state_transition(
    from_state="init",
    to_state="processing", 
    trigger="start_processing"
)

# Log warnings if needed
logger.log_warning("Processing warning", {"code": "W001"})

# Add custom metadata
logger.add_metadata("custom_field", "custom_value")

# End audit session
logger.end_audit(
    status=AuditStatus.SUCCESS,
    output_files=["output.json"]
)
```

### Automatic Component Integration

```python
class MyComponent(TotalOrderingBase):
    def __init__(self):
        super().__init__("MyComponent")
        self.stage_name = "A_analysis_nlp"
    
    def process(self, data=None, context=None):
        # Automatically uses audit logging if available
        if hasattr(self, 'process_with_audit'):
            return self.process_with_audit(data, context)
        
        # Standard processing with manual audit integration
        operation_id = self.generate_operation_id("process", {"data": data, "context": context})
        
        # ... processing logic ...
        
        return {
            "status": "success",
            "operation_id": operation_id,
            "result": "processing complete"
        }
```

### Error Handling

```python
try:
    # Component processing that might fail
    result = component.process(data, context)
except Exception as e:
    # Error is automatically captured in audit log
    logger.log_error(e, {"method": "process"})
    raise
```

## Configuration

### Environment Variables

- `AUDIT_ENABLED` - Enable/disable audit logging (default: enabled)
- `AUDIT_BASE_DIR` - Base directory for audit files (default: "canonical_flow")
- `AUDIT_PERFORMANCE_METRICS` - Enable performance metrics (default: enabled)

### Logger Configuration

```python
# Configure audit logger
logger = AuditLogger("ComponentName", "stage_name")
logger.enable_performance_metrics = True
logger.enable_state_tracking = True
logger.audit_base_dir = Path("custom/audit/path")
```

## Validation and Testing

### Validation Script

Run the validation script to test the audit system:

```bash
python3 validate_audit_system.py
```

This validates:
- Import functionality
- Audit logger creation
- Complete audit sessions
- File format compliance
- TotalOrderingBase integration
- Error handling

### Demo Scripts

- `demo_audit_system.py` - Comprehensive demonstration
- `demo_simple_audit.py` - Basic functionality demo
- `run_audit_validation.py` - Quick validation test

## Performance Considerations

### Overhead

The audit system is designed for minimal performance impact:
- Typical overhead: < 5ms per component execution
- Memory usage: < 10MB for typical audit sessions
- File I/O: Batched and optimized

### Optimization Features

- Lazy initialization of audit capabilities
- Optional performance metrics collection
- Graceful fallback when dependencies unavailable
- Configurable detail levels

## Best Practices

### Component Development

1. **Set stage_name** in component `__init__()` method
2. **Use process_with_audit** when available
3. **Provide meaningful document_stem** from input data
4. **Handle audit failures gracefully** in production

### Audit File Management

1. **Regular cleanup** of old audit files
2. **Archive** important audit sessions
3. **Monitor disk space** usage
4. **Rotate logs** in production environments

### Error Handling

1. **Log warnings** for non-critical issues
2. **Capture context** in error details
3. **Use appropriate status** levels
4. **Include recovery information** when applicable

## Dependencies

### Required
- Python 3.7+
- `json`, `time`, `datetime`, `pathlib` (standard library)

### Optional
- `psutil` - Enhanced performance metrics
- `platform` - System information (fallback available)

### Installation

No additional installation required - the audit system uses only standard library components with optional enhancements.

## Troubleshooting

### Common Issues

1. **Import Errors**
   - Ensure `audit_logger.py` and `total_ordering_base.py` are in Python path
   - Check for circular imports

2. **File Permission Errors**
   - Verify write permissions to `canonical_flow/` directory
   - Check disk space availability

3. **Missing Audit Files**
   - Confirm `document_stem` generation is working
   - Verify `stage_name` is set correctly
   - Check audit logger initialization

### Debug Mode

Enable debug logging:

```python
import logging
logging.basicConfig(level=logging.DEBUG)

# Audit operations will now log debug information
```

### File System Checks

```python
from pathlib import Path

# Check audit directory
audit_dir = Path("canonical_flow/A_analysis_nlp")
print(f"Directory exists: {audit_dir.exists()}")
print(f"Directory writable: {audit_dir.is_dir()}")

# Check recent audit files
if audit_dir.exists():
    audit_files = list(audit_dir.glob("*_audit.json"))
    print(f"Found {len(audit_files)} audit files")
```

## Security Considerations

### Data Privacy

- Audit files may contain sensitive processing data
- Consider encryption for audit files in production
- Implement appropriate access controls

### File System Security

- Audit files written with restricted permissions
- Directory traversal prevention in file paths
- Input validation for document stems

## Future Enhancements

### Planned Features

1. **Real-time monitoring** integration
2. **Audit file compression** for storage efficiency
3. **Distributed audit collection** for scaled deployments
4. **Advanced analytics** on audit data
5. **Automated anomaly detection** in execution patterns

### Integration Roadmap

1. **Complete A_analysis_nlp stage** - All 8 remaining components
2. **Extend to other stages** - R_search_retrieval, S_synthesis_output, etc.
3. **API integration** - REST endpoints for audit data
4. **Dashboard development** - Visual audit monitoring

## Support

For issues, questions, or enhancement requests related to the audit logging system:

1. Check this documentation
2. Run validation scripts
3. Review demo examples
4. Check existing audit files for patterns

## License

This audit logging system is part of the EGW Query Expansion project and follows the same licensing terms as the main project.